Initialized native services in: /Users/askowronski/.gradle/native
Initialized jansi services in: /Users/askowronski/.gradle/native
Received JVM installation metadata from '/Users/askowronski/Projects/TornadoVM/etc/dependencies/TornadoVM-jdk21/jdk-21.0.5.jdk/Contents/Home': {JAVA_HOME=/Users/askowronski/Projects/TornadoVM/etc/dependencies/TornadoVM-jdk21/jdk-21.0.5.jdk/Contents/Home, JAVA_VERSION=21.0.5, JAVA_VENDOR=Oracle Corporation, RUNTIME_NAME=Java(TM) SE Runtime Environment, RUNTIME_VERSION=21.0.5+9-LTS-239, VM_NAME=Java HotSpot(TM) 64-Bit Server VM, VM_VERSION=21.0.5+9-LTS-239, VM_VENDOR=Oracle Corporation, OS_ARCH=aarch64}
To honour the JVM settings for this build a single-use Daemon process will be forked. For more on this, please refer to https://docs.gradle.org/8.7/userguide/gradle_daemon.html#sec:disabling_the_daemon in the Gradle documentation.
Starting process 'Gradle build daemon'. Working directory: /Users/askowronski/.gradle/daemon/8.7 Command: /Users/askowronski/Projects/TornadoVM/etc/dependencies/TornadoVM-jdk21/jdk-21.0.5.jdk/Contents/Home/bin/java --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.prefs/java.util.prefs=ALL-UNNAMED --add-opens=java.base/java.nio.charset=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED -XX:MaxMetaspaceSize=384m -XX:+HeapDumpOnOutOfMemoryError -Xms256m -Xmx512m -Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.variant -cp /Users/askowronski/.gradle/wrapper/dists/gradle-8.7-bin/bhs2wmbdwecv87pi65oeuq5iu/gradle-8.7/lib/gradle-launcher-8.7.jar -javaagent:/Users/askowronski/.gradle/wrapper/dists/gradle-8.7-bin/bhs2wmbdwecv87pi65oeuq5iu/gradle-8.7/lib/agents/gradle-instrumentation-agent-8.7.jar org.gradle.launcher.daemon.bootstrap.GradleDaemon 8.7
Successfully started process 'Gradle build daemon'
An attempt to start the daemon took 0.828 secs.
The client will now receive all logging from the daemon (pid: 1610). The daemon log file: /Users/askowronski/.gradle/daemon/8.7/daemon-1610.out.log
Closing daemon's stdin at end of input.
The daemon will no longer process any standard input.
Daemon will be stopped at the end of the build 
Using 10 worker leases.
Received JVM installation metadata from '/Users/askowronski/Projects/TornadoVM/etc/dependencies/TornadoVM-jdk21/jdk-21.0.5.jdk/Contents/Home': {JAVA_HOME=/Users/askowronski/Projects/TornadoVM/etc/dependencies/TornadoVM-jdk21/jdk-21.0.5.jdk/Contents/Home, JAVA_VERSION=21.0.5, JAVA_VENDOR=Oracle Corporation, RUNTIME_NAME=Java(TM) SE Runtime Environment, RUNTIME_VERSION=21.0.5+9-LTS-239, VM_NAME=Java HotSpot(TM) 64-Bit Server VM, VM_VERSION=21.0.5+9-LTS-239, VM_VENDOR=Oracle Corporation, OS_ARCH=aarch64}
Watching the file system is configured to be enabled if available
Now considering [/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026] as hierarchies to watch
File system watching is active
Starting Build
Transforming foojay-resolver-0.9.0.jar (org.gradle.toolchains:foojay-resolver:0.9.0) with ExternalDependencyInstrumentingArtifactTransform
Transforming gson-2.10.1.jar (com.google.code.gson:gson:2.10.1) with ExternalDependencyInstrumentingArtifactTransform
Settings evaluated using settings file '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/settings.gradle.kts'.
Using local directory build cache for the root build (location = /Users/askowronski/.gradle/caches/build-cache-1, removeUnusedEntriesAfter = 7 days).
Projects loaded. Root project using build file '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/build.gradle.kts'.
Included projects: [root project 'conference-jvm-in-age-ai-2026', project ':demos', project ':tornadovm-demo', project ':demos:graalpy-java-host', project ':demos:java-llama-cpp', project ':demos:jcuda', project ':demos:tensorflow-ffm']

> Configure project :
Evaluating root project 'conference-jvm-in-age-ai-2026' using build file '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/build.gradle.kts'.

> Configure project :demos
Evaluating project ':demos' using build file '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/demos/build.gradle'.

> Configure project :tornadovm-demo
Evaluating project ':tornadovm-demo' using build file '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/tornadovm-demo/build.gradle.kts'.

> Configure project :demos:graalpy-java-host
Evaluating project ':demos:graalpy-java-host' using build file '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/demos/graalpy/java-host/build.gradle.kts'.

> Configure project :demos:java-llama-cpp
Evaluating project ':demos:java-llama-cpp' using build file '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/demos/java-llama-cpp/build.gradle.kts'.

> Configure project :demos:jcuda
Evaluating project ':demos:jcuda' using build file '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/demos/jcuda/build.gradle.kts'.

> Configure project :demos:tensorflow-ffm
Evaluating project ':demos:tensorflow-ffm' using build file '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/demos/tensorflow-ffm/build.gradle.kts'.
All projects evaluated.
Task path ':demos:java-llama-cpp:run' matched project ':demos:java-llama-cpp'
Task name matched 'run'
Selected primary task 'run' from project :demos:java-llama-cpp
Starting process 'command '/usr/libexec/java_home''. Working directory: /Users/askowronski/.gradle/daemon/8.7 Command: /usr/libexec/java_home -V
Successfully started process 'command '/usr/libexec/java_home''
Starting process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/temurin-22.0.2/Contents/Home/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm11864450430116628309probe Command: /Users/askowronski/Library/Java/JavaVirtualMachines/temurin-22.0.2/Contents/Home/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/temurin-22.0.2/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/askowronski/Library/Java/JavaVirtualMachines/temurin-22.0.2/Contents/Home': {JAVA_HOME=/Users/askowronski/Library/Java/JavaVirtualMachines/temurin-22.0.2/Contents/Home, JAVA_VERSION=22.0.2, JAVA_VENDOR=Eclipse Adoptium, RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=22.0.2+9, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=22.0.2+9, VM_VENDOR=Eclipse Adoptium, OS_ARCH=aarch64}
Starting process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/corretto-21.0.4/Contents/Home/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm13054992589700915900probe Command: /Users/askowronski/Library/Java/JavaVirtualMachines/corretto-21.0.4/Contents/Home/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/corretto-21.0.4/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/askowronski/Library/Java/JavaVirtualMachines/corretto-21.0.4/Contents/Home': {JAVA_HOME=/Users/askowronski/Library/Java/JavaVirtualMachines/corretto-21.0.4/Contents/Home, JAVA_VERSION=21.0.4, JAVA_VENDOR=Amazon.com Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=21.0.4+7-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=21.0.4+7-LTS, VM_VENDOR=Amazon.com Inc., OS_ARCH=aarch64}
Starting process 'command '/Users/askowronski/.sdkman/candidates/java/17.0.16-tem/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm2867829695681090245probe Command: /Users/askowronski/.sdkman/candidates/java/17.0.16-tem/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/.sdkman/candidates/java/17.0.16-tem/bin/java''
Received JVM installation metadata from '/Users/askowronski/.sdkman/candidates/java/17.0.16-tem': {JAVA_HOME=/Users/askowronski/.sdkman/candidates/java/17.0.16-tem, JAVA_VERSION=17.0.16, JAVA_VENDOR=Eclipse Adoptium, RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=17.0.16+8, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=17.0.16+8, VM_VENDOR=Eclipse Adoptium, OS_ARCH=aarch64}
Starting process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-17.0.8/Contents/Home/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm8300223725825150037probe Command: /Users/askowronski/Library/Java/JavaVirtualMachines/azul-17.0.8/Contents/Home/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-17.0.8/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-17.0.8/Contents/Home': {JAVA_HOME=/Users/askowronski/Library/Java/JavaVirtualMachines/azul-17.0.8/Contents/Home, JAVA_VERSION=17.0.8, JAVA_VENDOR=Azul Systems, Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=17.0.8+7-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=17.0.8+7-LTS, VM_VENDOR=Azul Systems, Inc., OS_ARCH=x86_64}
Starting process 'command '/Users/askowronski/.sdkman/candidates/java/21.0.8-librca/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm6190469483663453537probe Command: /Users/askowronski/.sdkman/candidates/java/21.0.8-librca/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/.sdkman/candidates/java/21.0.8-librca/bin/java''
Received JVM installation metadata from '/Users/askowronski/.sdkman/candidates/java/21.0.8-librca': {JAVA_HOME=/Users/askowronski/.sdkman/candidates/java/21.0.8-librca, JAVA_VERSION=21.0.8, JAVA_VENDOR=BellSoft, RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=21.0.8+12-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=21.0.8+12-LTS, VM_VENDOR=BellSoft, OS_ARCH=aarch64}
Starting process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-16.0.2/Contents/Home/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm6504305341268709233probe Command: /Users/askowronski/Library/Java/JavaVirtualMachines/azul-16.0.2/Contents/Home/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-16.0.2/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-16.0.2/Contents/Home': {JAVA_HOME=/Users/askowronski/Library/Java/JavaVirtualMachines/azul-16.0.2/Contents/Home, JAVA_VERSION=16.0.2, JAVA_VENDOR=Azul Systems, Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=16.0.2+7, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=16.0.2+7, VM_VENDOR=Azul Systems, Inc., OS_ARCH=aarch64}
Starting process 'command '/Users/askowronski/.gradle/jdks/azul_systems__inc_-8-aarch64-os_x.2/zulu-8.jdk/Contents/Home/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm13183719943204192530probe Command: /Users/askowronski/.gradle/jdks/azul_systems__inc_-8-aarch64-os_x.2/zulu-8.jdk/Contents/Home/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/.gradle/jdks/azul_systems__inc_-8-aarch64-os_x.2/zulu-8.jdk/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/askowronski/.gradle/jdks/azul_systems__inc_-8-aarch64-os_x.2/zulu-8.jdk/Contents/Home': {JAVA_HOME=/Users/askowronski/.gradle/jdks/azul_systems__inc_-8-aarch64-os_x.2/zulu-8.jdk/Contents/Home/jre, JAVA_VERSION=1.8.0_442, JAVA_VENDOR=Azul Systems, Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=1.8.0_442-b06, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=25.442-b06, VM_VENDOR=Azul Systems, Inc., OS_ARCH=aarch64}
Starting process 'command '/Users/askowronski/.sdkman/candidates/java/21.0.2-graalce/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm1229866598305774605probe Command: /Users/askowronski/.sdkman/candidates/java/21.0.2-graalce/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/.sdkman/candidates/java/21.0.2-graalce/bin/java''
Received JVM installation metadata from '/Users/askowronski/.sdkman/candidates/java/21.0.2-graalce': {JAVA_HOME=/Users/askowronski/.sdkman/candidates/java/21.0.2-graalce, JAVA_VERSION=21.0.2, JAVA_VENDOR=GraalVM Community, RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=21.0.2+13-jvmci-23.1-b30, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=21.0.2+13-jvmci-23.1-b30, VM_VENDOR=GraalVM Community, OS_ARCH=aarch64}
Starting process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-20.0.2/Contents/Home/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm5116663096215155739probe Command: /Users/askowronski/Library/Java/JavaVirtualMachines/azul-20.0.2/Contents/Home/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-20.0.2/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-20.0.2/Contents/Home': {JAVA_HOME=/Users/askowronski/Library/Java/JavaVirtualMachines/azul-20.0.2/Contents/Home, JAVA_VERSION=20.0.2, JAVA_VENDOR=Azul Systems, Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=20.0.2+9, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=20.0.2+9, VM_VENDOR=Azul Systems, Inc., OS_ARCH=aarch64}
Starting process 'command '/Users/askowronski/.gradle/jdks/eclipse_adoptium-11-aarch64-os_x.2/jdk-11.0.27+6/Contents/Home/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm7589671973871287844probe Command: /Users/askowronski/.gradle/jdks/eclipse_adoptium-11-aarch64-os_x.2/jdk-11.0.27+6/Contents/Home/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/.gradle/jdks/eclipse_adoptium-11-aarch64-os_x.2/jdk-11.0.27+6/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/askowronski/.gradle/jdks/eclipse_adoptium-11-aarch64-os_x.2/jdk-11.0.27+6/Contents/Home': {JAVA_HOME=/Users/askowronski/.gradle/jdks/eclipse_adoptium-11-aarch64-os_x.2/jdk-11.0.27+6/Contents/Home, JAVA_VERSION=11.0.27, JAVA_VENDOR=Eclipse Adoptium, RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=11.0.27+6, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=11.0.27+6, VM_VENDOR=Eclipse Adoptium, OS_ARCH=aarch64}
Starting process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-17.0.8.1/Contents/Home/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm3126156540718284638probe Command: /Users/askowronski/Library/Java/JavaVirtualMachines/azul-17.0.8.1/Contents/Home/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-17.0.8.1/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/askowronski/Library/Java/JavaVirtualMachines/azul-17.0.8.1/Contents/Home': {JAVA_HOME=/Users/askowronski/Library/Java/JavaVirtualMachines/azul-17.0.8.1/Contents/Home, JAVA_VERSION=17.0.8.1, JAVA_VENDOR=Azul Systems, Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=17.0.8.1+1-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=17.0.8.1+1-LTS, VM_VENDOR=Azul Systems, Inc., OS_ARCH=x86_64}
Starting process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/graalvm-ce-22.0.0/Contents/Home/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm14408206950116000746probe Command: /Users/askowronski/Library/Java/JavaVirtualMachines/graalvm-ce-22.0.0/Contents/Home/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/Library/Java/JavaVirtualMachines/graalvm-ce-22.0.0/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/askowronski/Library/Java/JavaVirtualMachines/graalvm-ce-22.0.0/Contents/Home': {JAVA_HOME=/Users/askowronski/Library/Java/JavaVirtualMachines/graalvm-ce-22.0.0/Contents/Home, JAVA_VERSION=22, JAVA_VENDOR=GraalVM Community, RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=22+36-jvmci-b02, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=22+36-jvmci-b02, VM_VENDOR=GraalVM Community, OS_ARCH=aarch64}
Starting process 'command '/Users/askowronski/.sdkman/candidates/java/25-tem/bin/java''. Working directory: /Users/askowronski/.gradle/.tmp/tmp-jvm7139077066070473891probe Command: /Users/askowronski/.sdkman/candidates/java/25-tem/bin/java -Xmx32m -Xms32m -cp . JavaProbe
Successfully started process 'command '/Users/askowronski/.sdkman/candidates/java/25-tem/bin/java''
Received JVM installation metadata from '/Users/askowronski/.sdkman/candidates/java/25-tem': {JAVA_HOME=/Users/askowronski/.sdkman/candidates/java/25-tem, JAVA_VERSION=25, JAVA_VENDOR=Eclipse Adoptium, RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=25+36-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=25+36-LTS, VM_VENDOR=Eclipse Adoptium, OS_ARCH=aarch64}
Tasks to be executed: [task ':demos:java-llama-cpp:compileJava', task ':demos:java-llama-cpp:processResources', task ':demos:java-llama-cpp:classes', task ':demos:java-llama-cpp:run']
Tasks that were excluded: []
Resolve mutations for :demos:java-llama-cpp:compileJava (Thread[#86,Execution worker,5,main]) started.
:demos:java-llama-cpp:compileJava (Thread[#86,Execution worker,5,main]) started.

> Task :demos:java-llama-cpp:compileJava UP-TO-DATE
Build cache key for task ':demos:java-llama-cpp:compileJava' is f7d0e7e90c3e4d6d7f164228d5b6004d
Skipping task ':demos:java-llama-cpp:compileJava' as it is up-to-date.
Resolve mutations for :demos:java-llama-cpp:processResources (Thread[#86,Execution worker,5,main]) started.
:demos:java-llama-cpp:processResources (Thread[#86,Execution worker,5,main]) started.

> Task :demos:java-llama-cpp:processResources NO-SOURCE
Skipping task ':demos:java-llama-cpp:processResources' as it has no source files and no previous output files.
Resolve mutations for :demos:java-llama-cpp:classes (Thread[#86,Execution worker,5,main]) started.
:demos:java-llama-cpp:classes (Thread[#86,Execution worker,5,main]) started.

> Task :demos:java-llama-cpp:classes UP-TO-DATE
Skipping task ':demos:java-llama-cpp:classes' as it has no actions.
Resolve mutations for :demos:java-llama-cpp:run (Thread[#86,Execution worker,5,main]) started.
:demos:java-llama-cpp:run (Thread[#86,Execution worker,5,main]) started.

> Task :demos:java-llama-cpp:run
Caching disabled for task ':demos:java-llama-cpp:run' because:
  Gradle would require more information to cache this task
Task ':demos:java-llama-cpp:run' is not up-to-date because:
  Task has not declared any outputs despite executing actions.
Starting process 'command '/Users/askowronski/.sdkman/candidates/java/25-tem/bin/java''. Working directory: /Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/demos/java-llama-cpp Command: /Users/askowronski/.sdkman/candidates/java/25-tem/bin/java -Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.variant -cp /Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/demos/java-llama-cpp/build/classes/java/main:/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/demos/java-llama-cpp/build/resources/main:/Users/askowronski/.gradle/caches/modules-2/files-2.1/de.kherud/llama/4.1.0/c6b6d6e61ce4a5d361f385d26ddf917c9682abbb/llama-4.1.0.jar:/Users/askowronski/.gradle/caches/modules-2/files-2.1/org.jetbrains/annotations/24.1.0/7af6a669488450c4a07c2c3254e2151df42d7d04/annotations-24.1.0.jar conf.jvm.llama.JavaLlamaCppDemo /Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/models/Llama-3.2-1B-Instruct-f16.gguf Tell me a short joke about programming.
Successfully started process 'command '/Users/askowronski/.sdkman/candidates/java/25-tem/bin/java''
[java-llama.cpp] ============================================================
[java-llama.cpp] java-llama.cpp Inference Demo
[java-llama.cpp] ============================================================
[java-llama.cpp] Java: 25
[java-llama.cpp] VM: OpenJDK 64-Bit Server VM
[java-llama.cpp] OS: Mac OS X aarch64
[java-llama.cpp] ============================================================

[java-llama.cpp] Checking model file...
[java-llama.cpp] Model file exists: /Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/models/Llama-3.2-1B-Instruct-f16.gguf
[java-llama.cpp] Model size: 2364 MB
[java-llama.cpp] Loading model...
[java-llama.cpp] Configuring model parameters...
/de/kherud/llama/Mac/aarch64
'ggml-metal.metal' not found
Extracted 'libjllama.dylib' to '/var/folders/6m/19snw3nx7kd9n124htss4ngw0000gn/T/libjllama.dylib'
WARNING: A restricted method in java.lang.System has been called
WARNING: java.lang.System::load has been called by de.kherud.llama.LlamaLoader in an unnamed module (file:/Users/askowronski/.gradle/caches/modules-2/files-2.1/de.kherud/llama/4.1.0/c6b6d6e61ce4a5d361f385d26ddf917c9682abbb/llama-4.1.0.jar)
WARNING: Use --enable-native-access=ALL-UNNAMED to avoid a warning for callers in this module
WARNING: Restricted methods will be blocked in a future release unless native access is enabled

srv  Java_de_kher: loading model '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/models/Llama-3.2-1B-Instruct-f16.gguf'
build: 4916 (c6af2161) with Apple clang version 15.0.0 (clang-1500.3.9.4) for arm64-apple-darwin23.6.0
system info: n_threads = 8, n_threads_batch = 8, total_threads = 10

system_info: n_threads = 8 (n_threads_batch = 8) / 10 | Metal : EMBED_LIBRARY = 1 | CPU : ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | LLAMAFILE = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | 

Java_de_kherud_llama_LlamaModel_loadModel: loading model
srv    load_model: loading model '/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/models/Llama-3.2-1B-Instruct-f16.gguf'
llama_model_load_from_file_impl: using device Metal (Apple M1 Pro) - 25558 MiB free
llama_model_loader: loaded meta data with 31 key-value pairs and 147 tensors from /Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026/models/Llama-3.2-1B-Instruct-f16.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 1B Instruct
llama_model_loader: - kv   3:                           general.finetune str              = Instruct
llama_model_loader: - kv   4:                           general.basename str              = Llama-3.2
llama_model_loader: - kv   5:                         general.size_label str              = 1B
llama_model_loader: - kv   6:                            general.license str              = llama3.2
llama_model_loader: - kv   7:                               general.tags arr[str,6]       = ["facebook", "meta", "pytorch", "llam...
llama_model_loader: - kv   8:                          general.languages arr[str,8]       = ["en", "de", "fr", "it", "pt", "hi", ...
llama_model_loader: - kv   9:                          llama.block_count u32              = 16
llama_model_loader: - kv  10:                       llama.context_length u32              = 131072
llama_model_loader: - kv  11:                     llama.embedding_length u32              = 2048
llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 8192
llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32
llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000
llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                 llama.attention.key_length u32              = 64
llama_model_loader: - kv  18:               llama.attention.value_length u32              = 64
llama_model_loader: - kv  19:                          general.file_type u32              = 1
llama_model_loader: - kv  20:                           llama.vocab_size u32              = 128256
llama_model_loader: - kv  21:                 llama.rope.dimension_count u32              = 64
llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = llama-bpe
llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,128256]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,280147]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 128000
llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 128009
llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {{- bos_token }}\n{%- if custom_tools ...
llama_model_loader: - kv  30:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   34 tensors
llama_model_loader: - type  f16:  113 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = F16
print_info: file size   = 2.30 GiB (16.00 BPW) 
load: special tokens cache size = 256
load: token to piece cache size = 0.7999 MB
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_embd           = 2048
print_info: n_layer          = 16
print_info: n_head           = 32
print_info: n_head_kv        = 8
print_info: n_rot            = 64
print_info: n_swa            = 0
print_info: n_swa_pattern    = 1
print_info: n_embd_head_k    = 64
print_info: n_embd_head_v    = 64
print_info: n_gqa            = 4
print_info: n_embd_k_gqa     = 512
print_info: n_embd_v_gqa     = 512
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8192
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: freq_base_train  = 500000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 1B
print_info: model params     = 1.24 B
print_info: general.name     = Llama 3.2 1B Instruct
print_info: vocab type       = BPE
print_info: n_vocab          = 128256
print_info: n_merges         = 280147
print_info: BOS token        = 128000 '<|begin_of_text|>'
print_info: EOS token        = 128009 '<|eot_id|>'
print_info: EOT token        = 128009 '<|eot_id|>'
print_info: EOM token        = 128008 '<|eom_id|>'
print_info: LF token         = 198 'Ċ'
print_info: EOG token        = 128008 '<|eom_id|>'
print_info: EOG token        = 128009 '<|eot_id|>'
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: offloading 16 repeating layers to GPU
load_tensors: offloading output layer to GPU
load_tensors: offloaded 17/17 layers to GPU
load_tensors: Metal_Mapped model buffer size =  2357.27 MiB
load_tensors:   CPU_Mapped model buffer size =   501.00 MiB
............................................................
llama_context: constructing llama_context
llama_context: n_seq_max     = 1
llama_context: n_ctx         = 4096
llama_context: n_ctx_per_seq = 4096
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = 0
llama_context: freq_base     = 500000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (4096) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M1 Pro
ggml_metal_init: picking default device: Apple M1 Pro
ggml_metal_load_library: using embedded metal library
ggml_metal_init: GPU name:   Apple M1 Pro
ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)
ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_init: GPU family: MTLGPUFamilyMetal4  (5002)
ggml_metal_init: simdgroup reduction   = true
ggml_metal_init: simdgroup matrix mul. = true
ggml_metal_init: has residency sets    = false
ggml_metal_init: has bfloat            = true
ggml_metal_init: use bfloat            = false
ggml_metal_init: hasUnifiedMemory      = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 26800.60 MB
ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)
ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)
ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)
ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)
ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)
ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)
ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)
ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)
ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)
ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)
ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)
ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)
ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)
ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)
ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)
ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)
ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)
ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)
ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)
llama_context:        CPU  output buffer size =     0.49 MiB
init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 16, can_shift = 1
init:      Metal KV buffer size =   128.00 MiB
llama_context: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB
llama_context:      Metal compute buffer size =   280.00 MiB
llama_context:        CPU compute buffer size =    12.01 MiB
llama_context: graph nodes  = 518
llama_context: graph splits = 2
common_init_from_params: setting dry_penalty_last_n to ctx_size = 4096
common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)
srv          init: initializing slots, n_slots = 1
slot         init: id  0 | task -1 | new slot n_ctx_slot = 4096
Java_de_kherud_llama_LlamaModel_loadModel: model loaded
Java_de_kherud_llama_LlamaModel_loadModel: chat template, chat_template: {{- bos_token }}
{%- if custom_tools is defined %}
    {%- set tools = custom_tools %}
{%- endif %}
{%- if not tools_in_user_message is defined %}
    {%- set tools_in_user_message = true %}
{%- endif %}
{%- if not date_string is defined %}
    {%- if strftime_now is defined %}
        {%- set date_string = strftime_now("%d %b %Y") %}
    {%- else %}
        {%- set date_string = "26 Jul 2024" %}
    {%- endif %}
{%- endif %}
{%- if not tools is defined %}
    {%- set tools = none %}
{%- endif %}

{#- This block extracts the system message, so we can slot it into the right place. #}
{%- if messages[0]['role'] == 'system' %}
[java-llama.cpp] Model loaded in     {%- set system_message = messages[0]['content']|trim %}
    {%- set messages = messages[1:] %}
{%- else %}
    {%- set system_message = "" %}
{%- endif %}

{#- System message #}
{{- "<|start_header_id|>system<|end_header_id|>\n\n" }}
{%- if tools is not none %}
    {{- "Environment: ipython\n" }}
{%- endif %}
{{- "Cutting Knowledge Date: December 2023\n" }}
{{- "Today Date: " + date_string + "\n\n" }}
{%- if tools is not none and not tools_in_user_message %}
    {{- "You have access to the following functions. To call a function, please respond with JSON for a function call." }}
    {{- 'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.' }}
    {{- "Do not use variables.\n\n" }}
    {%- for t in tools %}
        {{- t | tojson(indent=4) }}
        {{- "\n\n" }}
    {%- endfor %}
{%- endif %}
{{- system_message }}
{{- "<|eot_id|>" }}

{#- Custom tools are passed in a user message with some extra guidance #}
{%- if tools_in_user_message and not tools is none %}
    {#- Extract the first user message so we can plug it in here #}
    {%- if messages | length != 0 %}
        {%- set first_user_message = messages[0]['content']|trim %}
        {%- set messages = messages[1:] %}
    {%- else %}
        {{- raise_exception("Cannot put tools in the first user message when there's no first user message!") }}
{%- endif %}
    {{- '<|start_header_id|>user<|end_header_id|>\n\n' -}}
    {{- "Given the following functions, please respond with a JSON for a function call " }}
    {{- "with its proper arguments that best answers the given prompt.\n\n" }}
    {{- 'Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}.' }}
    {{- "Do not use variables.\n\n" }}
    {%- for t in tools %}
        {{- t | tojson(indent=4) }}
        {{- "\n\n" }}
    {%- endfor %}
    {{- first_user_message + "<|eot_id|>"}}
{%- endif %}

{%- for message in messages %}
    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}
        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' }}
    {%- elif 'tool_calls' in message %}
        {%- if not message.tool_calls|length == 1 %}
            {{- raise_exception("This model only supports single tool-calls at once!") }}
        {%- endif %}
        {%- set tool_call = message.tool_calls[0].function %}
        {{- '<|start_header_id|>assistant<|end_header_id|>\n\n' -}}
        {{- '{"name": "' + tool_call.name + '", ' }}
        {{- '"parameters": ' }}
        {{- tool_call.arguments | tojson }}
        {{- "}" }}
        {{- "<|eot_id|>" }}
    {%- elif message.role == "tool" or message.role == "ipython" %}
        {{- "<|start_header_id|>ipython<|end_header_id|>\n\n" }}
        {%- if message.content is mapping or message.content is iterable %}
            {{- message.content | tojson }}
        {%- else %}
            {{- message.content }}
        {%- endif %}
        {{- "<|eot_id|>" }}
    {%- endif %}
{%- endfor %}
{%- if add_generation_prompt %}
    {{- '<|start_header_id|>assistant<|end_header_id|>\n\n' }}
{%- endif %}
, example_format: '<|start_header_id|>system<|end_header_id|>

You are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>

Hello<|eot_id|><|start_header_id|>assistant<|end_header_id|>

Hi there<|eot_id|><|start_header_id|>user<|end_header_id|>

How are you?<|eot_id|><|start_header_id|>assistant<|end_header_id|>

'
srv  update_slots: all slots are idle
6.62s

[java-llama.cpp] Formatting prompt with Llama 3.2 chat template...
[java-llama.cpp] Prompt: Tell me a short joke about programming.
[java-llama.cpp] ----------------------------------------
[java-llama.cpp] Response:
[java-llama.cpp] Configuring inference parameters (temp=0.7)...
[java-llama.cpp] Starting inference...
check_double_bos_eos: Added a BOS token to the prompt as specified by the model but the prompt also starts with a BOS token. So now the final prompt starts with 2 BOS tokens. Are you sure this is what you want?
slot launch_slot_: id  0 | task 0 | processing task
slot update_slots: id  0 | task 0 | new prompt, n_ctx_slot = 4096, n_keep = 0, n_prompt_tokens = 30
slot update_slots: id  0 | task 0 | kv cache rm [0, end)
slot update_slots: id  0 | task 0 | prompt processing progress, n_past = 30, n_tokens = 30, progress = 1.000000
slot update_slots: id  0 | task 0 | prompt done, n_past = 30, n_tokens = 30
Here's one:

Why do programmers prefer dark mode?

Because light attracts bugs.slot      release: id  0 | task 0 | stop processing: n_past = 46, truncated = 0
slot print_timing: id  0 | task 0 | 
prompt eval time =      50.43 ms /    30 tokens (    1.68 ms per token,   594.90 tokens per second)
       eval time =     277.74 ms /    17 tokens (   16.34 ms per token,    61.21 tokens per second)

[java-llama.cpp] ----------------------------------------

[java-llama.cpp] Stats:
      total time =     328.16 ms /    47 tokens
srv  update_slots: all slots are idle
[java-llama.cpp]   Model load time: 6.62s
[java-llama.cpp]   Inference time: 0.33s
[java-llama.cpp]   Tokens generated: 18
[java-llama.cpp]   Tokens/sec: 54.71

[java-llama.cpp] Demo completed successfully!

BUILD SUCCESSFUL in 16s
2 actionable tasks: 1 executed, 1 up-to-date
Watched directory hierarchies: [/Users/askowronski/Priv/talks/conference-jvm-in-age-ai-2026]
