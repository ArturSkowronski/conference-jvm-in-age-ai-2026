# JVM in the Age of AI â€” Docker Benchmark Results

**Generated**: Wed Jan 28 21:07:38 UTC 2026
**Host**: 75e1239b4917
**Image**: jvm-ai-benchmark

## Environment

| Property | Value |
|----------|-------|
| OS | Linux x86_64 |
| RAM | 14 GB |
| NVIDIA GPU | Tesla T4 |
| CUDA Driver | 570.195.03 |
| CUDA Toolkit | 12.6 |
| JDK 25 | 25.0.3-beta |
| JDK 21 | 21.0.10 |
| TornadoVM | /opt/tornadovm/tornadovm-2.2.0-ptx (backend: ptx) |

## Results

| Demo | Result |
|------|--------|
| Llama3.java (JDK 21) | FAILED (exit 1) |
| Llama3.java (JDK 25 Temurin) | FAILED (exit 1) |
| java-llama.cpp | FAILED (exit 1) |
| JCuda | OK (11s) |
| TornadoVM VectorAdd | FAILED (exit 1) |
| TornadoVM GPULlama3 | FAILED (exit 1) |
| TensorFlow FFM | OK (16s) |
| GraalPy Java Host | OK (18s) |

## Notes

- Model: Llama-3.2-1B-Instruct-f16.gguf (FP16, ~2.5GB)
- TornadoVM uses PTX backend (NVIDIA CUDA)
- java-llama.cpp runs in CPU mode (prebuilt Maven native)
- Individual demo logs saved alongside this report
