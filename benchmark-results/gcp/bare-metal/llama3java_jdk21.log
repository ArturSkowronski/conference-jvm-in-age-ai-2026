============================================================
Llama3.java - Pure Java LLM Inference
============================================================
Java: java version "21.0.10" 2026-01-20 LTS
Model: /home/askowronski/.llama/models/Llama-3.2-1B-Instruct-f16.gguf
Mode: --instruct
============================================================

WARNING: Using incubator modules: jdk.incubator.vector
Note: /home/askowronski/benchmark/demos/llama3-java/Llama3.java uses preview features of Java SE 21.
Note: Recompile with -Xlint:preview for details.
Parse /home/askowronski/.llama/models/Llama-3.2-1B-Instruct-f16.gguf: 1411 millis
Load LlaMa model: 626 millis
Here's one:

Why did the programmer quit his job?

Because he didn
context: 33/32 prompt: 0.50 tokens/s (18) generation: 0.52 tokens/s (15)
