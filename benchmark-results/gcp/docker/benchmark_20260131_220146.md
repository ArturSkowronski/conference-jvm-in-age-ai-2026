# JVM in the Age of AI â€” Docker Benchmark Results

**Generated**: Sat Jan 31 22:14:59 UTC 2026
**Host**: e468078a24db
**Image**: jvm-ai-benchmark

## Environment

| Property | Value |
|----------|-------|
| OS | Linux x86_64 |
| RAM | 14 GB |
| NVIDIA GPU | Tesla T4 |
| CUDA Driver | 570.211.01 |
| CUDA Toolkit | 12.6 |
| JDK 25 | 25.0.3-beta |
| JDK 21 | 21.0.10 |
| TornadoVM | /opt/tornadovm/tornadovm-2.2.0-opencl (backend: opencl) |

## Results

| Demo | Result |
|------|--------|
| Llama3.java (JDK 21) | OK: 0.49 tok/s (73s) |
| Llama3.java (JDK 25 Temurin) | OK: 5.05 tok/s (12s) |
| java-llama.cpp | OK: 76.34 tok/s (15s) |
| JCuda | OK (12s) |
| TornadoVM VectorAdd | OK (5s) |
| TornadoVM GPULlama3 | OK: 19.18 tok/s (37s) |
| Cyfra LLM | TIMEOUT (600s) |
| TensorFlow FFM | OK (18s) |
| GraalPy Java Host | OK (19s) |

## Notes

- Model: Llama-3.2-1B-Instruct-f16.gguf (FP16, ~2.5GB)
- TornadoVM uses OpenCL backend (NVIDIA GPU)
- java-llama.cpp uses CUDA-built native with GPU offload (all layers)
- Individual demo logs saved alongside this report
