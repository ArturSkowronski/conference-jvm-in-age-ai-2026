# JVM in the Age of AI â€” Docker Benchmark Results

**Generated**: Thu Jan 29 15:24:34 UTC 2026
**Host**: cfccbc5cedcc
**Image**: jvm-ai-benchmark

## Environment

| Property | Value |
|----------|-------|
| OS | Linux x86_64 |
| RAM | 14 GB |
| NVIDIA GPU | Tesla T4 |
| CUDA Driver | 570.211.01 |
| CUDA Toolkit | 12.6 |
| JDK 25 | 25.0.3-beta |
| JDK 21 | 21.0.10 |
| TornadoVM | /opt/tornadovm/tornadovm-2.2.0-opencl (backend: opencl) |

## Results

| Demo | Result |
|------|--------|
| Llama3.java (JDK 21) | OK: 0.52 tok/s (65s) |
| Llama3.java (JDK 25 Temurin) | OK: 4.76 tok/s (11s) |
| java-llama.cpp | OK: 65.48 tok/s (19s) |
| JCuda | OK (12s) |
| TornadoVM VectorAdd | OK (9s) |
| TornadoVM GPULlama3 | OK (33s) |
| TensorFlow FFM | OK (16s) |
| GraalPy Java Host | OK (17s) |

## Notes

- Model: Llama-3.2-1B-Instruct-f16.gguf (FP16, ~2.5GB)
- TornadoVM uses OpenCL backend (NVIDIA GPU)
- java-llama.cpp uses CUDA-built native with GPU offload (all layers)
- Individual demo logs saved alongside this report
