# JVM in the Age of AI â€” Docker Benchmark Results

**Generated**: Wed Jan 28 21:24:20 UTC 2026
**Host**: 63864b67fa81
**Image**: jvm-ai-benchmark

## Environment

| Property | Value |
|----------|-------|
| OS | Linux x86_64 |
| RAM | 14 GB |
| NVIDIA GPU | Tesla T4 |
| CUDA Driver | 570.195.03 |
| CUDA Toolkit | 12.6 |
| JDK 25 | 25.0.3-beta |
| JDK 21 | 21.0.10 |
| TornadoVM | /opt/tornadovm/tornadovm-2.2.0-opencl (backend: opencl) |

## Results

| Demo | Result |
|------|--------|
| Llama3.java (JDK 21) | OK: 0.55 tok/s (60s) |
| Llama3.java (JDK 25 Temurin) | OK: 5.13 tok/s (11s) |
| java-llama.cpp | OK: 6.42 tok/s (16s) |
| JCuda | OK (10s) |
| TornadoVM VectorAdd | OK (5s) |
| TornadoVM GPULlama3 | OK (22s) |
| TensorFlow FFM | OK (16s) |
| GraalPy Java Host | OK (16s) |

## Notes

- Model: Llama-3.2-1B-Instruct-f16.gguf (FP16, ~2.5GB)
- TornadoVM uses PTX backend (NVIDIA CUDA)
- java-llama.cpp runs in CPU mode (prebuilt Maven native)
- Individual demo logs saved alongside this report
